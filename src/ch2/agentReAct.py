import re, os

from loguru import logger

from client import LLMClient
from executor import ToolExecutor
from tools import search
from util import load_system_prompt


class ReActAgent:
    def __init__(self, llm_client: LLMClient, tool_executor: ToolExecutor, system_prompt_tmpl: str, max_steps: int = 5):
        self.llm_client = llm_client
        self.tool_executor = tool_executor
        self.max_steps = max_steps
        self.history = []
        self.system_prompt_tmpl = system_prompt_tmpl

    def _parse_output(self, text: str):
        """è§£æLLMçš„è¾“å‡ºï¼Œæå–Thoughtå’ŒActionã€‚"""
        thought_match = re.search(r"Thought: (.*)", text) # ä¸åŒ…æ‹¬æ¢è¡Œç¬¦
        action_match = re.search(r"Action: (.*)", text)
        thought = thought_match.group(1).strip() if thought_match else None
        action = action_match.group(1).strip() if action_match else None
        return thought, action

    def _parse_action(self, action_text: str):
        """è§£æActionå­—ç¬¦ä¸²ï¼Œæå–å·¥å…·åç§°å’Œè¾“å…¥ã€‚"""
        match = re.match(r"(\w+)\[(.*)\]", action_text)
        if match:
            return match.group(1), match.group(2)
        return None, None

    def run(self, question: str):
        """
        è¿è¡ŒReActæ™ºèƒ½ä½“æ¥å›ç­”ä¸€ä¸ªé—®é¢˜ã€‚
        """
        self.history = [] # æ¯æ¬¡è¿è¡Œæ—¶é‡ç½®å†å²è®°å½•
        current_step = 0

        while current_step < self.max_steps:
            current_step += 1
            logger.info(f"--- ç¬¬ {current_step} æ­¥ ---")

            # 1. æ ¼å¼åŒ–æç¤ºè¯
            tools_desc = self.tool_executor.getAvailableTools()
            history_str = "\n".join(self.history)
            prompt = self.system_prompt_tmpl.format(
                tools=tools_desc,
                question=question,
                history=history_str
            )

            logger.info(f"ğŸ“ å½“å‰æç¤ºè¯: \n{prompt}\n")

            # 2. è°ƒç”¨LLMè¿›è¡Œæ€è€ƒ
            messages = [{"role": "user", "content": prompt}]
            response_text = self.llm_client.think(messages=messages)
            
            if not response_text:
                logger.error("é”™è¯¯:LLMæœªèƒ½è¿”å›æœ‰æ•ˆå“åº”ã€‚")
                break

            # 3. è§£æLLMçš„è¾“å‡º
            thought, action = self._parse_output(response_text)
            
            if thought:
                logger.info(f"æ€è€ƒ: {thought}")

            if not action:
                logger.warning("è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                break

            # 4. æ‰§è¡ŒAction
            if action.startswith("Finish"):
                # å¦‚æœæ˜¯FinishæŒ‡ä»¤ï¼Œæå–æœ€ç»ˆç­”æ¡ˆå¹¶ç»“æŸ
                final_answer = re.match(r"Finish\[(.*)\]", action).group(1)
                logger.info(f"ğŸ‰ æœ€ç»ˆç­”æ¡ˆ: {final_answer}")
                return final_answer
            
            tool_name, tool_input = self._parse_action(action)
            if not tool_name or not tool_input:
                # ... å¤„ç†æ— æ•ˆActionæ ¼å¼ ...
                continue

            logger.info(f"ğŸ¬ è¡ŒåŠ¨: {tool_name}[{tool_input}]")
            
            tool_function = self.tool_executor.getTool(tool_name)
            if not tool_function:
                observation = f"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚"
            else:
                observation = tool_function(tool_input) # è°ƒç”¨çœŸå®å·¥å…·

            
            logger.info(f"ğŸ‘€ è§‚å¯Ÿ: {observation}")
            
            # å°†æœ¬è½®çš„Actionå’ŒObservationæ·»åŠ åˆ°å†å²è®°å½•ä¸­
            self.history.append(f"Action: {action}")
            self.history.append(f"Observation: {observation}")

        # å¾ªç¯ç»“æŸ
        logger.info("å·²è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")


if __name__ == '__main__':
    prompt_file = "./prompts/promptReAct.txt"
    system_prompt_tmpl = load_system_prompt(prompt_file)
    llm = LLMClient()
    tool_executor = ToolExecutor()
    search_desc = "ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚"
    tool_executor.registerTool("Search", search_desc, search)
    agent = ReActAgent(llm_client=llm, tool_executor=tool_executor, system_prompt_tmpl=system_prompt_tmpl)
    question = "googleæœ€æ–°çš„æ‰‹æœºæ˜¯å“ªä¸€æ¬¾ï¼Ÿå®ƒçš„ä¸»è¦å–ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
    agent.run(question)

